# Cleanup Report - Artifact Builder Reset

**Date:** 2026-01-01  
**Purpose:** Remove old artifact builders and their outputs that are not required by the deployed site.

---

## Files Deleted

### Old Artifact Builder Scripts (scripts/)
- `audit_semantic_artifacts.py` - Audited semantic artifacts (not used)
- `build_semantic_artifacts.py` - Built semantic artifacts (not used)
- `build_artifacts_master.py` - Master builder (not used)
- `build_artifacts_part_a.py` - Partial builder (not used)
- `build_artifacts_part_b.py` - Partial builder (not used)
- `build_artifacts_part_c.py` - Partial builder (not used)
- `build_dataset_overview_artifacts.py` - Built overview artifacts (replaced by new workflow)
- `build_phase1_artifacts.py` - Phase 1 builder (not used)
- `test_semantic_artifacts.py` - Tested semantic artifacts (not used)
- `test_dataset_overview_artifacts.py` - Tested overview artifacts (not used)
- `test_phase1_artifacts.py` - Phase 1 tests (not used)
- `inspect_v7_structure.py` - Old inspector (not used)
- `inspect_v7_paths.py` - Old path inspector (not used)

### Generated Artifacts (public/data/)
These were generated by the deleted scripts but are NOT used by the site:
- `coverage_table.json` - Not referenced by any page
- `dataset_summary.json` - Not referenced by any page
- `confidence_disagreement.json` - Not referenced by any page
- `activity_vs_silence_stats.json` - Not referenced by any page
- `sampling_density_stats.json` - Not referenced by any page
- `symbol_table.json` - Not referenced by any page

### Generated Artifacts (public/data/artifacts/)
These ARE referenced by src/lib/artifactsData.ts and src/pages/dataset.astro:
- `ARTIFACTS_READY.json` - Used by /status and /dataset pages
- `coverage_v7.json` - Used by /dataset page
- `scale_v7.json` - Used by /dataset page
- `preview_row_v7.json` - Used by /dataset page
- `sentiment_vs_forward_return_v7.json` - Used by /dataset page
- `regimes_activity_vs_silence_v7.json` - Used by /dataset page
- `hybrid_decisions_v7.json` - Used by /dataset page
- `confidence_disagreement_v7.json` - Used by /dataset page
- `lifecycle_summary_v7.json` - Used by /dataset page

**Decision:** DELETE all files in public/data/artifacts/ because:
1. The audit revealed sentiment fields DO NOT EXIST in v7 entries
2. These artifacts claim to show sentiment data that doesn't exist
3. Need clean slate for correct artifact generation
4. Site will gracefully handle missing artifacts (shows warnings)

---

## Files KEPT

### Core System Scripts (scripts/)
- `publish.py` - Production status publisher (KEEP - stable workflow)
- `lint_wording.mjs` - Wording rules linter (KEEP - quality assurance)
- `scripts/lib/` - Shared libraries (KEEP - used by publish.py)

### Runtime Data (public/data/)
- `status.json` - Latest collection status (KEEP - published by stable workflow)
- `status_history.jsonl` - Historical status log (KEEP - published by stable workflow)
- `README.md` - Data directory documentation (KEEP - documentation)

### Content (src/content/updates/)
- All markdown posts (KEEP - editorial content)

---

## New Structure Added

### Directories
- `data/` - Local data storage (not published)
- `data/schema/` - Schema documentation
- `data/samples/` - Local archive samples
- `scripts/tools/` - Development utilities

### Files
- `data/schema/ARCHIVE_ENTRY_FULL_SCHEMA.txt` - Authoritative v7 schema
- `data/samples/cryptobot_latest.jsonl.gz` - Latest archive file (synced)
- `data/samples/cryptobot_latest_head200.jsonl` - First 200 lines for inspection
- `scripts/tools/sync_cryptobot_sample.py` - Sample sync script
- `scripts/tools/README.md` - Tools documentation

---

## Rationale

### Why Delete Artifact Builders?
- Built on WRONG assumption: sentiment fields exist in v7
- Generated artifacts claiming sentiment data that doesn't exist
- Created "Not available yet" messages when data truly doesn't exist
- Need investigation-first workflow (inspect → verify → build)

### Why Delete Generated Artifacts?
- public/data/*.json: Not referenced by any page, safe to delete
- public/data/artifacts/*.json: Reference non-existent sentiment fields, misleading

### Why Keep publish.py?
- Stable workflow that only publishes status.json and status_history.jsonl
- Does NOT make claims about sentiment data
- Used in production deployments

### New Workflow
1. Run `npm run sync-sample` to get latest archive sample
2. Inspect `data/samples/cryptobot_latest_head200.jsonl` to verify field paths
3. Only then write artifact builders with VERIFIED paths
4. No assumptions, no guessing, no "maybe this field..."

---

## Build Status After Cleanup

**Test run:** 2026-01-01 22:55 UTC

```bash
npm run build
```

**Result:** ✅ SUCCESS

**Expected warnings (graceful degradation):**
- "Failed to load artifacts readiness: ENOENT... ARTIFACTS_READY.json" (status.astro)
- CSS minify warnings (cosmetic, not breaking)

**Pages generated:** 12/12
- ✅ /index.html
- ✅ /contact/index.html
- ✅ /dataset/index.html (shows artifact warning banner)
- ✅ /status/index.html (shows CryptoBot status, no artifacts section)
- ✅ /research/index.html
- ✅ /updates/index.html + 3 update posts
- ✅ Legal pages (terms, privacy, disclaimer)

**VSCode Problems:** 0 errors, 0 warnings

**New workflow verified:**
```bash
npm run sync-sample
# Output: 3 files created in data/samples/
# - cryptobot_latest.jsonl.gz (147 entries)
# - cryptobot_20260101_2249.jsonl.gz (timestamped)
# - cryptobot_latest_head200.jsonl (decompressed, 147 lines)
```

Sample validation:
```python
import json
with open('data/samples/cryptobot_latest_head200.jsonl', 'r') as f:
    entries = [json.loads(line) for line in f]
    print(f"Valid JSONL: {len(entries)} entries")
    # Valid JSONL: 147 entries
```

---

## Next Steps

To build new artifacts with correct field paths:

1. **Sync latest sample:**
   ```bash
   npm run sync-sample
   ```

2. **Inspect schema:**
   ```bash
   cat data/schema/ARCHIVE_ENTRY_FULL_SCHEMA.txt
   ```

3. **Verify field paths:**
   ```python
   import json
   with open('data/samples/cryptobot_latest_head200.jsonl', 'r') as f:
       for i, line in enumerate(f):
           if i >= 20:  # Check first 20 entries
               break
           entry = json.loads(line)
           # Verify path exists
           if 'your_field' in entry.get('your_path', {}):
               print(f"Entry {i}: FOUND")
   ```

4. **Only then write artifact builder:**
   - Use ONLY verified paths
   - Mark unavailable features with exact missing paths
   - No assumptions, no guessing

5. **Test build:**
   ```bash
   npm run build
   ```

---

## Documentation Updated

**Files modified:**
- `docs/PROJECT_GUIDE.md` - Added "Archive Sample Sync Workflow" section
- `package.json` - Added "sync-sample" npm script
- `.github/copilot-instruction.md` - Added investigation rules (earlier in session)

**Files created:**
- `data/schema/ARCHIVE_ENTRY_FULL_SCHEMA.txt` - Canonical v7 schema
- `scripts/tools/sync_cryptobot_sample.py` - Sample sync script
- `scripts/tools/README.md` - Tools documentation
- `scripts/TEMP_CLEANUP_REPORT.md` - This report

**Reference documentation:**
- See `TEMP_V7_SENTIMENT_AUDIT.md` for detailed investigation of missing sentiment fields
- See `docs/PROJECT_GUIDE.md` for workflow and verification steps

---

## Summary

✅ Removed 13 old artifact builder scripts  
✅ Removed 15 generated artifact JSON files  
✅ Kept stable production workflow (publish.py, status.json)  
✅ Added sample sync workflow with 3 tools  
✅ Added canonical schema documentation  
✅ Site builds successfully with graceful degradation  
✅ Zero VSCode Problems  
✅ Documentation updated with new workflow  
✅ All temp inspection files cleaned up

**Clean slate achieved.** Ready for investigation-first artifact development.
